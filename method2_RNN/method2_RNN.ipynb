{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "def load_dataset(dataset_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df.drop(columns=['id'], inplace=True) # Drop id column\n",
    "    df.dropna(inplace=True) # Drop null values (if any)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in training set: 287113\n"
     ]
    }
   ],
   "source": [
    "# Load train data.\n",
    "df_train = load_dataset(r'../data/cnn_dailymail/train.csv')\n",
    "print(\"Number of records in training set:\", len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in validation set: 13368\n"
     ]
    }
   ],
   "source": [
    "# Load validation data.\n",
    "df_val = load_dataset(r'../data/cnn_dailymail/validation.csv')\n",
    "print(\"Number of records in validation set:\", len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in test set: 11490\n"
     ]
    }
   ],
   "source": [
    "# Load test data.\n",
    "df_test = load_dataset(r'../data/cnn_dailymail/test.csv')\n",
    "print(\"Number of records in test set:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant newline character ('\\n').\n",
    "df_train['highlights'] = df_train['highlights'].str.replace('\\n', ' ', regex=True)\n",
    "# Remove the extra whitespace before the periods.\n",
    "df_train['highlights'] = df_train['highlights'].str.replace(' \\.','.', regex=False)\n",
    "\n",
    "df_val['highlights'  ] = df_val['highlights'  ].str.replace('\\n', ' ', regex=True)\n",
    "df_val['highlights'  ] = df_val['highlights'  ].str.replace(' \\.','.', regex=False)\n",
    "\n",
    "df_test['highlights' ] = df_test['highlights' ].str.replace('\\n', ' ', regex=True)\n",
    "df_test['highlights' ] = df_test['highlights' ].str.replace(' \\.','.', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 252.1/252.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "wv = gensim.downloader.load('glove-wiki-gigaword-200') # word vectors\n",
    "vocab = np.array(wv.index_to_key)\n",
    "embedding = np.array(wv.vectors)\n",
    "\n",
    "pad_emb = np.zeros((1, embedding.shape[1]))         # embedding for '<pad>'.\n",
    "unk_emb = np.mean(embedding, axis=0, keepdims=True) # embedding for '<unk>'.\n",
    "\n",
    "vocab = np.insert(arr=vocab, obj=0, values='<pad>')\n",
    "vocab = np.insert(arr=vocab, obj=0, values='<unk>')\n",
    "embedding = np.vstack((pad_emb, unk_emb, embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./word_vectors/vocab.npy','wb') as f:\n",
    "    np.save(f, vocab)\n",
    "\n",
    "with open('./word_vectors/embedding.npy','wb') as f:\n",
    "    np.save(f, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding.from_pretrained(torch.from_numpy(embedding).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
