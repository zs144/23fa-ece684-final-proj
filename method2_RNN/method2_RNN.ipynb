{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import nltk\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "def load_dataset(dataset_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df.drop(columns=['id'], inplace=True) # Drop id column\n",
    "    df.dropna(inplace=True) # Drop null values (if any)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in training set: 287113\n"
     ]
    }
   ],
   "source": [
    "# Load train data.\n",
    "df_train = load_dataset(r'../data/cnn_dailymail/train.csv')\n",
    "print(\"Number of records in training set:\", len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in validation set: 13368\n"
     ]
    }
   ],
   "source": [
    "# Load validation data.\n",
    "df_val = load_dataset(r'../data/cnn_dailymail/validation.csv')\n",
    "print(\"Number of records in validation set:\", len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in test set: 11490\n"
     ]
    }
   ],
   "source": [
    "# Load test data.\n",
    "df_test = load_dataset(r'../data/cnn_dailymail/test.csv')\n",
    "print(\"Number of records in test set:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant newline character ('\\n').\n",
    "df_train['highlights'] = df_train['highlights'].str.replace('\\n', ' ')\n",
    "# Remove the extra whitespace before the periods.\n",
    "df_train['highlights'] = df_train['highlights'].str.replace(r' \\.', r'.')\n",
    "\n",
    "df_val['highlights'  ] = df_val['highlights'  ].str.replace('\\n', ' ')\n",
    "df_val['highlights'  ] = df_val['highlights'  ].str.replace(r' \\.', r'.')\n",
    "\n",
    "df_test['highlights' ] = df_test['highlights' ].str.replace('\\n', ' ')\n",
    "df_test['highlights' ] = df_test['highlights' ].str.replace(r' \\.', r'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Sentence Encoding\n",
    "\n",
    "In this step, we write a function to encode any given sentence into a vector representation. To do this, we first use the GloVe word embedding (`glove-wiki-gigaword-200`) to convert each single word in the sentence into a vector $\\mathbf{w}i$, which has 200 elements. Then, we simply average these vectors to get the sentence representation $\\mathbf{s}_j = \\frac{1}{L_j}\\sum_{i=1}^{L_j} \\mathbf{w}_j$, where $L_j$ is the length of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = gensim.downloader.load('glove-wiki-gigaword-200') # word vectors\n",
    "encoding_len = 200\n",
    "\n",
    "try:\n",
    "    vocab = np.load(file='./word_vectors/vocab.npy')\n",
    "    embedding = np.load(file='./word_vectors/embedding.npy')\n",
    "    pad_emb = np.zeros((encoding_len))   # embedding for '<pad>'.\n",
    "    unk_emb = np.mean(embedding, axis=0) # embedding for '<unk>'.\n",
    "except:\n",
    "    vocab = np.array(wv.index_to_key)\n",
    "    embedding = np.array(wv.vectors)\n",
    "\n",
    "    pad_emb = np.zeros((encoding_len))   # embedding for '<pad>'.\n",
    "    unk_emb = np.mean(embedding, axis=0) # embedding for '<unk>'.\n",
    "\n",
    "    vocab = np.insert(arr=vocab, obj=0, values='<pad>')\n",
    "    vocab = np.insert(arr=vocab, obj=0, values='<unk>')\n",
    "    embedding = np.vstack((pad_emb, unk_emb, embedding))\n",
    "    with open('./word_vectors/vocab.npy','wb') as f:\n",
    "        np.save(f, vocab)\n",
    "    with open('./word_vectors/embedding.npy','wb') as f:\n",
    "        np.save(f, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_train['article'][0]\n",
    "sents = nltk.tokenize.sent_tokenize(text)\n",
    "sent_lens = [len(sent) for sent in sents]\n",
    "avg_sent_len = sum(sent_lens) / len(sent_lens)\n",
    "sents = [sent for sent in sents if len(sent) > avg_sent_len * 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October.',\n",
       " 'The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.',\n",
       " 'Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A .',\n",
       " \"State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure.\",\n",
       " 'The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A.',\n",
       " 'The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month.',\n",
       " 'Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort.',\n",
       " 'Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sent: str, wv: KeyedVectors, unk_emb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Encode the sentence into a 200-dimensional vector.\n",
    "    \"\"\"\n",
    "    encoded = []\n",
    "    for word in sent.split():\n",
    "        word = word.lower()\n",
    "        if word in wv:\n",
    "            encoded.append(np.array(wv[word]))\n",
    "        else:\n",
    "            encoded.append(unk_emb)\n",
    "    encoded = np.array(encoded).mean(axis=0)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_article(article: list[str], pad_emb: np.ndarray):\n",
    "    # TODO: get to know the output type, and then implement this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Sentence Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.dropout(input)\n",
    "        output, hidden = self.gru(input)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long,\n",
    "                                    device=device).fill_(0) # Start of Document\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
