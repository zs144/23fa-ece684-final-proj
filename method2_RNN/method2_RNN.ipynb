{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "def load_dataset(dataset_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df.drop(columns=['id'], inplace=True) # Drop id column\n",
    "    df.dropna(inplace=True) # Drop null values (if any)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in training set: 287113\n"
     ]
    }
   ],
   "source": [
    "# Load train data.\n",
    "df_train = load_dataset(r'../data/cnn_dailymail/train.csv')\n",
    "print(\"Number of records in training set:\", len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in validation set: 13368\n"
     ]
    }
   ],
   "source": [
    "# Load validation data.\n",
    "df_val = load_dataset(r'../data/cnn_dailymail/validation.csv')\n",
    "print(\"Number of records in validation set:\", len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in test set: 11490\n"
     ]
    }
   ],
   "source": [
    "# Load test data.\n",
    "df_test = load_dataset(r'../data/cnn_dailymail/test.csv')\n",
    "print(\"Number of records in test set:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant newline character ('\\n').\n",
    "df_train['highlights'] = df_train['highlights'].str.replace('\\n', ' ')\n",
    "# Remove the extra whitespace before the periods.\n",
    "df_train['highlights'] = df_train['highlights'].str.replace(r' \\.', r'.')\n",
    "\n",
    "df_val['highlights'  ] = df_val['highlights'  ].str.replace('\\n', ' ')\n",
    "df_val['highlights'  ] = df_val['highlights'  ].str.replace(r' \\.', r'.')\n",
    "\n",
    "df_test['highlights' ] = df_test['highlights' ].str.replace('\\n', ' ')\n",
    "df_test['highlights' ] = df_test['highlights' ].str.replace(r' \\.', r'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Sentence Encoding\n",
    "\n",
    "In this step, we write a function to encode any given sentence into a vector representation. To do this, we first use the GloVe word embedding (specifically `glove-wiki-gigaword-200`) to convert each single word in the sentence into a vector $\\mathbf{w}i$, which has 200 elements. Then, we simply average these vectors to get the sentence representation $\\mathbf{s}_i = \\sum{i=1}^{l_i} \\mathbf{w}_i$, where $l_i$ is the length of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vocab = open('./word_vectors/vocab.npy','rb')\n",
    "    embedding = open('./word_vectors/embedding.npy','rb')\n",
    "except:\n",
    "    wv = gensim.downloader.load('glove-wiki-gigaword-200') # word vectors\n",
    "    vocab = np.array(wv.index_to_key)\n",
    "    embedding = np.array(wv.vectors)\n",
    "\n",
    "    pad_emb = np.zeros((1, embedding.shape[1]))         # embedding for '<pad>'.\n",
    "    unk_emb = np.mean(embedding, axis=0, keepdims=True) # embedding for '<unk>'.\n",
    "\n",
    "    vocab = np.insert(arr=vocab, obj=0, values='<pad>')\n",
    "    vocab = np.insert(arr=vocab, obj=0, values='<unk>')\n",
    "    embedding = np.vstack((pad_emb, unk_emb, embedding))\n",
    "    with open('./word_vectors/vocab.npy','wb') as f:\n",
    "        np.save(f, vocab)\n",
    "    with open('./word_vectors/embedding.npy','wb') as f:\n",
    "        np.save(f, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding.from_pretrained(torch.from_numpy(embedding).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Sentence Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.dropout(input)\n",
    "        output, hidden = self.gru(input)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
